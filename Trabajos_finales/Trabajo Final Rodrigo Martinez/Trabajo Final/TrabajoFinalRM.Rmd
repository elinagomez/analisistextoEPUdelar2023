---
title: "Trabajo Final - Rodrigo Martinez"
author: "R aplicado al análisis cualitativo (EP/FCS)"
date: "`r Sys.Date()`"
output: pdf_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

El presente documento obrará de trabajo final del curso "R aplicado al análisis cualitativo", impartido por la docente Elina Gomez, como programa de Educación Permanente de la Facultad de Ciencias Sociales (FCS), Universidad de la República (Udelar). El cursado del mismo transcurrió entre los meses de noviembre y diciembre del año 2022, acumulando una carga horaria de 20 horas totales.

El objetivo del trabajo será aplicar algunas de las técnicas de análisis cualitativo sobre texto aprendidas durante el curso. Para ello, se analizarán las tres revistas académicas de investigación más importantes de nuestro servicio universitario, las cuales son publicadas desde la institución misma. Estas son la Revista de Ciencias Sociales (del Departamento de Sociología (DS)), la Revista Uruguaya de Ciencia Política (publicada por el Departamento de Ciencia Política (DCP)) y la Revista Fronteras (del Departamento de Trabajo Social (DTS)).

El ejercicio constará de tres objetivos específicos:

1.  Realizar una comparación de los temas de investigación de los artículos publicados en las mencionadas revistas, con la intención de identificar el grado de pluralidad de los objetos de investigación. Se utilizará como indicador *proxy* a las palabras clave asignadas a cada pesquisa. Esto permitirá hacer una evaluación sobre qué temáticas de investigación son divulgadas con mayor frecuencia desde nuestro servicio universitario (en general), así como habilitará la (eventual) identificación de límites y/o superposiciones disciplinarias.

2.  Diagramar redes de co-ocurrencia entre las distintas temáticas investigadas, con la intención de determinar cuáles temas se estudian más frecuentemente con otros, y cuáles de manera más aislada.

3.  Contabilizar la frecuencia con la que integrantes de cada unidad académica son mencionados o citados por sus colegas en otros departamentos. De esta forma, se podrá realizar una aproximación a mensurar el nivel de colaboración y/o influencia interdisciplinaria de nuestro servicio. Se utilizará como listado de referencia a una lista otorgada por Sección Personal y Decanato FCS-Udelar en el pasado mes de diciembre.

Los números incorporados para el análisis son, para el caso de la RCCSS y la RUCP, todos aquellos posteriores a 2003 (inclusive). En el caso de Fronteras, se incluyeron todos los números posteriores a 2009 (inclusive). La diferencia de alcance temporal se fundamenta en la inaccesibilidad de los números anteriores en el caso de Fronteras.

Carga de paquetes necesarios para la realización del ejercicio:

```{r pressure}
library(readtext)
library(dplyr)
library(quanteda) 
library(stringr)
library(quanteda.textstats)
library(quanteda.textplots)
library(ggplot2)
```

## Comparación temáticas de las investigación publicadas en las tres principales revistas académicas institucionales de la FCS-Udelar

Los pasos llevados adelante son los siguientes. Se explican de manera detallada para la RCCSS, mas se obvian para las otras dos ya que constan de operaciones idénticas (salvo los ajustes pertinentes de cada caso).

Se separan los chunks porque algunos comandos son de ejecución pesada y requieren que se agrege el parámetro "cache=TRUE". De esta forma, se evita la pérdida de tiempo. 

```{r, cache=TRUE}
#Revista de Ciencias Sociales

#1:Se importa la base desde un archivo PDF. El mismo son todos los números desde el año 2003 al presente de la Revista de Ciencias Sociales (RCCSS). La unificación de los distintos PDFs se realizó a través de servicios online (IlovePDF y similares).
setwd("C:/Users/Usuario/Documents/rcuali2022/Trabajos finales/Trabajo Final Rodrigo Martinez/Trabajo Final")
RCCSS <- readtext("RCCSS (2003 al presente).pdf")

#2:Se crea variable de revista con la etiqueta RCCSS.

RCCSS = RCCSS %>% mutate(revista="RCCSS")

#3: Se "tokeniza" cada palabra de la RCCSS, sin eliminar la puntuación.

toks <- tokens(RCCSS$text,
               remove_punct = FALSE,
               remove_numbers = TRUE)

#4: Se asigna a la variable creada como etiqueta.

docnames(toks) <- RCCSS$revista ##tiene que tener la misma dimensión que la base que tokenizaste

#5: Se ubica cada vez que en el documento se escribió "palabras clave" y se trae las cincuenta palabras anteriores y posteriores.

Palabras_ClaveRCCSS <- kwic(toks, 
                       pattern = quanteda::phrase(c("palabras clave")),
                       window = 50)

#6: Elimino casos que no corresponden: estos se entienden como aquellos que no cuentan con la palabra "abstract" de manera cercana al término de referencia. Estos son casos en los que se usó "palabras clave" con otros fines.

Palabras_ClaveRCCSS =  slice(Palabras_ClaveRCCSS,grep("Abstract",Palabras_ClaveRCCSS$post))

#7: Transformo a data frame y me quedo solamente con la variable del texto posterior al término de referencia ("palabras clave") y la etiqueta de la revista

Palabras_ClaveRCCSS = as_tibble(Palabras_ClaveRCCSS) %>% transmute(docname,
                                                         post)

#8: Elimino los dos puntos al principio de cada celda.

Palabras_ClaveRCCSS$post = substr(Palabras_ClaveRCCSS$post,3,1000) #Saco dos puntos al principio

#9: "Tokenizo" las palabras clave, asigno etiqueta y ubico las palabras en torno al término "abstract". 
toks2 <- tokens(Palabras_ClaveRCCSS$post)
docnames(toks2) <- Palabras_ClaveRCCSS$docname ##tiene que tener la misma dimensión que la base que tokenizaste
Palabras_ClaveRCCSS2 <- kwic(toks2, 
                       pattern = quanteda::phrase(c("abstract")),
                       window = 50)

#10: Transformo a data frame y me quedo solamente con la variable del texto previo al término de referencia ("abstract") y la etiqueta de la revista. De esta manera, elimino palabras que no interesan.

Palabras_ClaveRCCSS2 = as_tibble(Palabras_ClaveRCCSS2) %>% transmute(docname,
                                                         pre)

#11: Elimino los puntos finales en aquellas celdas que finalicen con uno.

Palabras_ClaveRCCSS2$pre = ifelse(substr(Palabras_ClaveRCCSS2$pre,nchar(Palabras_ClaveRCCSS2$pre),nchar(Palabras_ClaveRCCSS2$pre))==".",
                                  substr(Palabras_ClaveRCCSS2$pre,1,nchar(Palabras_ClaveRCCSS2$pre)-1),
                                  Palabras_ClaveRCCSS2$pre)
```

```{r}
#12: Separo las palabras clave según separadores de la revista. Debido a que en algunas ocasiones se usa la barra ( / ) y en otras la coma ( , ), debí hacerlo en dos pasos y luego unificar las filas. Asimismo, debí utilizar como referencia el uso y desuso de barras debido a que algunos casos podían usar barra y coma a la vez. En definitiva, cuando se usó barra, se aplicó a esta como separador. Cuando no se usó barras, se separó por coma. Además, se extrajeron hasta seis palabras clave, que fue el máximo identificado (a través de la prueba manual de seguir agregando columnas).

convarsRCCSS = bind_rows(
            Palabras_ClaveRCCSS2[grep("/",Palabras_ClaveRCCSS2$pre),] %>% 
            tidyr::separate(col=pre,
                            into = c("X1","X2","X3","X4","X5","X6"),
                            sep="/"),
            Palabras_ClaveRCCSS2[c(1:196)[-grep("/",Palabras_ClaveRCCSS2$pre)],] %>% 
            tidyr::separate(col=pre,
                            into = c("X1","X2","X3","X4","X5","X6"),
                            sep=","))

#13: Se crea vector con las palabras clave extraidas y se quitan espacios al principio.

palabras=str_trim(c(convarsRCCSS$X1, convarsRCCSS$X2,convarsRCCSS$X3,convarsRCCSS$X4,
                    convarsRCCSS$X5,convarsRCCSS$X6))

#14: Debido a que se identifica que en algunos casos el texto no tiene el formato habitual (es decir, con la palabra "abstract" seguidamente después de las palabras clave), lo cual conservó el texto irrelevante para los fines de este trabajo, se eliminan los casos de palabras clave que tengan más de 40 caracteres. Aunque se perdieron algunas palabras clave, se evalúa razonable dicha perdida por la escasez de tiempo para la entrega del trabajo y porque no se detectó sesgos temáticos.

palabras=c(ifelse(nchar(palabras)<40,palabras,NA)) #Elimino términos con más de 40 caracteres porque son errores. Pierdo algo de información pero bueno.

#15: Elimino los valores NA del vector.

palabras = palabras[!is.na(palabras)]

#16: Se elabora diccionario con vector de cada columna

dic_palabras = quanteda::dictionary(list(palabras=palabras))

#17: Se realiza la matriz de términos, un documento por fila y las palabras clave en columnas. Me quedo con las palabras de más de 2 caracteres y mencionadas al menos 3 veces. 

dfm <- quanteda::dfm(quanteda::tokens_compound(quanteda::tokens(Palabras_ClaveRCCSS2$pre,
                                                                remove_punct = TRUE,
                                                                remove_numbers = TRUE),
                                               dic_palabras),
                     tolower = TRUE,  
                     verbose = FALSE) %>% 
  quanteda::dfm_remove(pattern = c(quanteda::stopwords("english")), 
                       min_nchar=3) %>% 
  quanteda::dfm_trim(min_termfreq = 3)

#18: Imprimo nube de palabras de los temas más investigados en la RCCSS

quanteda.textplots::textplot_wordcloud(dfm, min_count = 3,max_words = 100,
                                       random.order = FALSE,
                                       colors = RColorBrewer::brewer.pal(8,"Dark2"),
                                       comparison = F)
```
Como se visualiza en la primera nube de palabras, la RCCSS incorpora como términos clave más mencionados a las temáticas de género, trabajo, violencia, educación, juventud, pandemia, políticas públicas y negociación colectiva. Asimismo, se encuentran con menos menciones cuestiones de suicidio, pobreza, desarrollo, derechos humanos, desigualdades sociales, segregación urbana, democracia, seguridad, discapacidad, movimientos sociales, entre otros. 

```{r, cache=TRUE}
#Revista Uruguaya de Ciencia Política

RUCP <- readtext("/Users/rodrigomartinez/Downloads/Revistas/RUCP (2003 al presente).pdf")

RUCP = RUCP %>% mutate(revista="RUCP")

toksCP <- tokens(RUCP$text,
               remove_punct = FALSE,
               remove_numbers = TRUE)
docnames(toksCP) <- RUCP$revista 
Palabras_ClaveRUCP <- kwic(toksCP, 
                            pattern = quanteda::phrase(c("palabras clave")),
                            window = 50)

Palabras_ClaveRUCP =  slice(Palabras_ClaveRUCP,grep("Abstract",Palabras_ClaveRUCP$post)) 

Palabras_ClaveRUCP = as_tibble(Palabras_ClaveRUCP) %>% transmute(docname,
                                                                   post)

Palabras_ClaveRUCP$post = substr(Palabras_ClaveRUCP$post,3,1000) 

toksCP2 <- tokens(Palabras_ClaveRUCP$post)
docnames(toksCP2) <- Palabras_ClaveRUCP$docname 
Palabras_ClaveRUCP2 <- kwic(toksCP2, 
                             pattern = quanteda::phrase(c("abstract")),
                             window = 50)

Palabras_ClaveRUCP2 = as_tibble(Palabras_ClaveRUCP2) %>% transmute(docname,
                                                                     pre)

Palabras_ClaveRUCP2$pre = ifelse(substr(Palabras_ClaveRUCP2$pre,nchar(Palabras_ClaveRUCP2$pre),nchar(Palabras_ClaveRUCP2$pre))==".",
                                  substr(Palabras_ClaveRUCP2$pre,1,nchar(Palabras_ClaveRUCP2$pre)-1),
                                 Palabras_ClaveRUCP2$pre)
```

```{r}
convarsRUCP = bind_rows(Palabras_ClaveRUCP2[c(1:133)[-grep(";",Palabras_ClaveRUCP2$pre)],] %>% 
                           tidyr::separate(col=pre,
                                           into = c("X1","X2","X3","X4","X5","X6","X7","X8"),
                                           sep=","),
                           Palabras_ClaveRUCP2[grep(";",Palabras_ClaveRUCP2$pre),] %>% 
                           tidyr::separate(col=pre,
                                           into = c("X1","X2","X3","X4","X5","X6","X7","X8"),
                                           sep=";"))

palabrasRUCP=str_trim(c(convarsRUCP$X1, convarsRUCP$X2,convarsRUCP$X3,convarsRUCP$X4,
                    convarsRUCP$X5,convarsRUCP$X6,convarsRUCP$X7,convarsRUCP$X8)) 

palabrasRUCP=c(ifelse(nchar(palabrasRUCP)<40,palabrasRUCP,NA)) 

palabrasRUCP=palabrasRUCP[!is.na(palabrasRUCP)] 

dic_palabrasRUCP = quanteda::dictionary(list(palabrasRUCP=palabrasRUCP))

dfmRUCP <- quanteda::dfm(quanteda::tokens_compound(quanteda::tokens(Palabras_ClaveRUCP2$pre,
                                                                remove_punct = TRUE,
                                                                remove_numbers = TRUE),
                                                   dic_palabrasRUCP),
                     tolower = TRUE,  
                     verbose = FALSE) %>% 
  quanteda::dfm_remove(pattern = c(quanteda::stopwords("english")), 
                       min_nchar=3) %>% 
  quanteda::dfm_trim(min_termfreq = 2) 

quanteda.textplots::textplot_wordcloud(dfmRUCP, min_count = 3,max_words = 100,
                                       random.order = FALSE,
                                       colors = RColorBrewer::brewer.pal(8,"Dark2"),
                                       comparison = F)
```
Al poner foco en la segunda nube de palabras, se aprecia el cambio disciplinario a la Ciencia Política. Los términos más mencionados de la RUCP fueron los partidos políticos, la democracia, la política comparada, el regionalismo, la reforma, los partidos y distintos países de la región. Otros términos menos mencionados fueron las elecciones, política, gobierno, carreras políticas, Mercosur, políticas públicas o sociales, política subnacional, opinión pública, entre otros. 

En ambas revistas el término más mencionado fue “Uruguay”, lo que da cuenta de cierta preponderancia de los estudios de caso nacional. Empero, se visualizan más menciones de otros países en la RUCP. 


```{r, cache=TRUE}
Fronteras <- readtext("/Users/rodrigomartinez/Downloads/Revistas/Fronteras (2009 al presente).pdf")

Fronteras = Fronteras %>% mutate(revista="Fronteras")

toksTS <- tokens(Fronteras$text,
                 remove_punct = FALSE,
                 remove_numbers = TRUE)
docnames(toksTS) <- Fronteras$revista ##tiene que tener la misma dimensión que la base que tokenizaste
Palabras_ClaveFronteras <- kwic(toksTS, 
                           pattern = quanteda::phrase(c("palabras clave")),
                           window = 50)

Palabras_ClaveFronteras =  slice(Palabras_ClaveFronteras,grep("Abstract",Palabras_ClaveFronteras$post)) 

Palabras_ClaveFronteras = as_tibble(Palabras_ClaveFronteras) %>% transmute(docname,
                                                                   post)

Palabras_ClaveFronteras$post = substr(Palabras_ClaveFronteras$post,3,1000) 

toksTS2 <- tokens(Palabras_ClaveFronteras$post)
docnames(toksTS2) <- Palabras_ClaveFronteras$docname 
Palabras_ClaveFronteras2 <- kwic(toksTS2, 
                             pattern = quanteda::phrase(c("abstract")),
                             window = 50)

Palabras_ClaveFronteras2 = as_tibble(Palabras_ClaveFronteras2) %>% transmute(docname,
                                                                     pre)

Palabras_ClaveFronteras2$pre = ifelse(substr(Palabras_ClaveFronteras2$pre,nchar(Palabras_ClaveFronteras2$pre),nchar(Palabras_ClaveFronteras2$pre))==".",substr(Palabras_ClaveFronteras2$pre,1,nchar(Palabras_ClaveFronteras2$pre)-1),
                                 Palabras_ClaveFronteras2$pre)
```

```{r}
convarsFronteras = Palabras_ClaveFronteras2 %>% 
                           tidyr::separate(col=pre,
                                           into = c("X1","X2","X3","X4","X5","X6"),
                                           sep=",")

palabrasFronteras=str_trim(c(convarsFronteras$X1, convarsFronteras$X2,convarsFronteras$X3,
                             convarsFronteras$X4,convarsFronteras$X5,convarsFronteras$X6)) 

palabrasFronteras=c(ifelse(nchar(palabrasFronteras)<40,palabrasFronteras,NA)) 

palabrasFronteras=palabrasFronteras[!is.na(palabrasFronteras)] 

dic_palabrasFronteras = quanteda::dictionary(list(palabrasFronteras=palabrasFronteras))

dfmFronteras <- quanteda::dfm(quanteda::tokens_compound(quanteda::tokens(Palabras_ClaveFronteras2$pre,
                                                                remove_punct = TRUE,
                                                                remove_numbers = TRUE),
                                                   dic_palabrasFronteras),
                     tolower = TRUE,  
                     verbose = FALSE) %>% 
  quanteda::dfm_remove(pattern = c(quanteda::stopwords("english")), 
                       min_nchar=3) %>% 
  quanteda::dfm_trim(min_termfreq = 2) 

quanteda.textplots::textplot_wordcloud(dfmFronteras, min_count = 2, max_words = 100,
                                       random.order = FALSE,
                                       colors = RColorBrewer::brewer.pal(8,"Dark2"),
                                       comparison = F)
```
En la tercera nube de palabras nos encontramos con las palabras claves de la Revista Fronteras. El término más mencionado es el nombre de la disciplina (“Trabajo Social”), seguido por salud mental, género, políticas públicas, estado, neoliberalismo, derechos humanos y personas mayores. Cabe mencionar que el número de palabras aquí es menor debido a que la cantidad de números de revista incorporados fue menor. Por ello, el argumento “min_count” fue configurado para el valor 2, de manera de mostrar todas las palabras reiteradas al menos una vez. 

En definitiva, en esta primera parte podemos ver que si bien hay algunos temas superpuestos entre las investigaciones de las distintas revistas (las políticas públicas, el estado, las políticas sociales, el género, los derechos humanos), la compartimentación disciplinaria es tangible.

## Redes de co-ocurrencia entre las temáticas de las investigaciones en cada una de las revistas analizadas

El objetivo de este segundo punto es presentar las redes de los términos clave, para representar gráficamente como ciertos temas se vinculan con otros y cuáles se estudian de manera más aislada.

En el caso de la RCCSS encontramos una serie de temáticas entrelazadas: género, trabajo, pobreza, políticas, social y diálogo social, negociación colectiva y revitalización sindical y relaciones laborales, desarrollo, tecnología y cultura. Además, se visualiza otro grupo de términos en torno a la educación: pandemia, TIC, juventud, transiciones, brecha e inclusión digital. Finalmente, vemos que hay algunas áreas de estudio separadas: desarrollo rural y agricultura familiar, desigualdades sociales y segregación urbana, violencia y jóvenes, delitos y víctimas. 

En el caso de la RUCP se encuentran cinco redes principales, que evidencian distintos objetos o acercamientos dentro de la Ciencia Política. La red más importante es la de los estudios de política comparada. Allí están varios países latinoamericanos y los términos “elecciones, congreso, partidos y sistemas de partidos, etc. Luego vemos una serie de temas vinculados a Chile: Think tanks, régimen autoritario, transición a la democracia, políticas públicas. En tercer lugar, se visualiza una red vinculada a las Fuerzas Armadas y la justicia en Uruguay. En cuarto lugar, uno de relaciones internacionales (regionalismo, Mercosur, geopolítica). En quinto lugar, se vislumbran investigaciones de corte cualitativo e históricas (identidad política, ethos discursivo, relato, pasado reciente). 

Finalmente, la Revista Fronteras enseña solamente dos redes. Una donde se trabajan temas de derechos humanos y salud mental, mientras la otra abarca cuestiones de género, políticas sociales, personas mayores y adolescencias.  

```{r}
#Revista de Ciencias Sociales

base_fcm1 = dfm %>%
  fcm(context = "document")

feat1 <- names(topfeatures(base_fcm1, 100)) ##cambia la cantidad de palabras
base_fcm_select1 <- fcm_select(base_fcm1, pattern = feat1, selection = "keep")
size1 <- log(colSums(dfm_select(base_fcm1, feat1, selection = "keep")))

set.seed(144)
quanteda.textplots::textplot_network(base_fcm_select1, 
                                     min_freq = 0.8, 
                                     vertex_size = size1 / max(size1) * 3,
                                     edge_color="#eb6864")

#Revista Uruguaya de Ciencia Política

base_fcm2 = dfmRUCP %>%
  fcm(context = "document")

feat2 <- names(topfeatures(base_fcm2, 100)) ##cambia la cantidad de palabras
base_fcm_select2 <- fcm_select(base_fcm2, pattern = feat2, selection = "keep")
size2 <- log(colSums(dfm_select(base_fcm2, feat2, selection = "keep")))

set.seed(144)
quanteda.textplots::textplot_network(base_fcm_select2, 
                                     min_freq = 0.8, 
                                     vertex_size = size2 / max(size2) * 3,
                                     edge_color="#eb6864")

#Revista Fronteras

base_fcm3 = dfmFronteras %>%
  fcm(context = "document")

feat3 <- names(topfeatures(base_fcm3, 100)) ##cambia la cantidad de palabras
base_fcm_select3 <- fcm_select(base_fcm3, pattern = feat3, selection = "keep")
size3 <- log(colSums(dfm_select(base_fcm3, feat3, selection = "keep")))

set.seed(144)
quanteda.textplots::textplot_network(base_fcm_select3, 
                                     min_freq = 0.8, 
                                     vertex_size = size3 / max(size3) * 3,
                                     edge_color="#eb6864")

```

##Influencia entre Unidades Académicas de FCS-Udelar

Este último punto tiene el objetivo de identificar el grado de influencia y/o colaboración entre las Unidades Académicas de nuestro servicio universitario.

La metodología aquí empleada tiene las siguientes falencias:
1. No distingue entre colaboración (investigaciones en coautoría) e influencia (citas);
2. No logré realizar la búsqueda de términos incorporando apellido y primera letra del nombre (debido que al tokenizar separó por palabras y tampoco habían patrones claros como para usar separadores). Por ello, solamente busqué apellidos, lo cual es mucho más impreciso. Sin embargo, a los efectos de este ejercicio, evalué que no resultaría grave.

Como se visualiza en la tabla 1, parece que la medición tiene cierto sentido. Los miembros de las Unidades Académicas más mencionadas se corresponden con aquellas donde las revistas son publicadas: Fronteras y el DTS (46%), la RCCSS y el DS (49%), la RUCP y el DCP (47%). En cuanto a las menciones entre Unidades, se identifica que el grado de influencia es relativamente similar entre los Departamentos de Trabajo Social, Sociología y Ciencia Política. Estos varían entre el 15 y 19% de las menciones en las revistas que no son de su propia unidad. Asimismo, se observa cierta paridad entre el DECON y la Unidad Multidisciplinaria, como las dos Unidades Académicas menos presentes en las revistas analizadas. Esto podría ser indicio de un desarrollo institucional más incipiente, lo que deriva en menos investigaciones o investigadores a mencionar. Otra hipótesis alternativa es que los tópicos de investigación son distintos a los de las revistas estudiadas y que los límites disciplinarios se encuentran más demarcados. Dar explicación de esto excede los objetivos de este trabajo.

```{r}

#Importo listado de docentes

library(readxl)
listadoDocentes <- read_excel("ListadoDocentes.xlsx")

#Creo diccionario

dicunidades <- dictionary(list(
  DCP = c(ifelse(listadoDocentes$Unidad_Académica=="Ciencia Política",listadoDocentes$Citas,NA)[!is.na(ifelse(listadoDocentes$Unidad_Académica=="Ciencia Política",listadoDocentes$Citas,NA))]),
  DS = c(ifelse(listadoDocentes$Unidad_Académica=="Sociología",listadoDocentes$Citas,NA)[!is.na(ifelse(listadoDocentes$Unidad_Académica=="Sociología",listadoDocentes$Citas,NA))]),
  DECON = c(ifelse(listadoDocentes$Unidad_Académica=="Economía",listadoDocentes$Citas,NA)[!is.na(ifelse(listadoDocentes$Unidad_Académica=="Economía",listadoDocentes$Citas,NA))]),
  DTS = c(ifelse(listadoDocentes$Unidad_Académica=="Trabajo Social",listadoDocentes$Citas,NA)[!is.na(ifelse(listadoDocentes$Unidad_Académica=="Trabajo Social",listadoDocentes$Citas,NA))]),
  MULTI = c(ifelse(listadoDocentes$Unidad_Académica=="Unidad Multidisciplinaria",listadoDocentes$Citas,NA)[!is.na(ifelse(listadoDocentes$Unidad_Académica=="Unidad Multidisciplinaria",listadoDocentes$Citas,NA))])
  ))

#Creo DFM de RCCSS

dfmBibliografiaRCCSS <- quanteda::dfm(quanteda::tokens(toks, #con tokens se separa el texto en que cada palabra sea un texto (y permite crear el DFM)
                                                           remove_punct = TRUE, ##saco puntuación
                                                           remove_numbers = TRUE), #saco números
                                          tolower=TRUE, #paso a minúsculas. El verbose de abajo te escribe lo que hace o lo que recoge. No sirve mucho y enlentece la operación
                                          verbose = FALSE) %>% 
  quanteda::dfm_remove(min_nchar=3)

#Busco según diccionario creado en RCCSS

midic_resultRCCSS <- dfm_lookup(dfmBibliografiaRCCSS,dictionary=dicunidades)

#Creo DFM de RUCP

dfmBibliografiaRUCP <- quanteda::dfm(quanteda::tokens(toksCP, #con tokens se separa el texto en que cada palabra sea un texto (y permite crear el DFM)
                                                      remove_punct = TRUE, ##saco puntuación
                                                      remove_numbers = TRUE), #saco números
                                     tolower=TRUE, #paso a minúsculas. El verbose de abajo te escribe lo que hace o lo que recoge. No sirve mucho y enlentece la operación
                                     verbose = FALSE) %>% 
  quanteda::dfm_remove(min_nchar=3)

#Busco según diccionario creado en RUCP

midic_resultRUCP <- dfm_lookup(dfmBibliografiaRUCP,dictionary=dicunidades)

#Creo DFM de Fronteras

dfmBibliografiaFronteras <- quanteda::dfm(quanteda::tokens(toksTS, #con tokens se separa el texto en que cada palabra sea un texto (y permite crear el DFM)
                                            remove_punct = TRUE, ##saco puntuación
                                            remove_numbers = TRUE), #saco números
                           tolower=TRUE, #paso a minúsculas. El verbose de abajo te escribe lo que hace o lo que recoge. No sirve mucho y enlentece la operación
                           verbose = FALSE) %>% 
  quanteda::dfm_remove(min_nchar=3)

#Busco según diccionario creado en Fronteras

midic_resultFronteras<-dfm_lookup(dfmBibliografiaFronteras,dictionary=dicunidades)

#Creo data frame con resultados de las tres

influencia = bind_rows(convert(midic_resultRCCSS, to = "data.frame"),
          convert(midic_resultRUCP, to = "data.frame"),
          convert(midic_resultFronteras, to = "data.frame"))

#Paso de formato wide a formato long

influencia_long = reshape2::melt(influencia,id.vars="doc_id")

#Modifico nombres de variables

influencia_long = influencia_long %>%  
  rename(Revista = doc_id) %>% 
  rename(Menciones = value) %>% 
  rename(UA = variable)

#Reordeno tabla

influencia_long = influencia_long[order(influencia_long$Revista),]

influencia_long = influencia_long %>% 
  group_by(Revista) %>% 
  mutate(Porcentaje=Menciones/sum(Menciones)) %>% 
  arrange(Revista,-Porcentaje)

#Imprimo tabla

kable(influencia_long, 
      format = "simple",
      caption = "Tabla 1. Menciones de docentes de FCS en revistas institucionales según su Unidad Académica",
      col.names = c("Revista", "Unidad Académica", "Menciones","Porcentaje"), 
      align=c("lcc")) #Estilizo tabla
```
